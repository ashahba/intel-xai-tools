{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afda1ef1-2239-41c5-8513-1e6e7971db27",
   "metadata": {},
   "source": [
    "In this notebook, we will download a model, dataset, and metric from Hugigng Face Hub and generate a interactive HTML Model Card using Intel AI Safety Model Card Generator Tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe569b-4b8f-4128-ade7-307546f5f61c",
   "metadata": {},
   "source": [
    "## 1. Download and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307063bb-2faf-4482-9f22-d92c49d0a7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate datasets transformers[torch] scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a0486-b5cc-4f0d-965d-4eba91cad62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intel_ai_safety.model_card_gen.model_card_gen import ModelCardGen\n",
    "from datasets import load_dataset, load_metric\n",
    "import evaluate\n",
    "from transformers import AutoConfig,AutoModelForSequenceClassification,AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e688b17f-623b-482b-930f-fee122a51da6",
   "metadata": {},
   "source": [
    "## 2. Download Dataset from Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf04f4-9a72-46c4-a3bd-197fff3bfb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(\"hatexplain\")\n",
    "he_dataset = raw_dataset.map(lambda e: {'text': \" \".join(e['post_tokens'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea1f80-900f-48b6-b10f-1d12a29d0ee7",
   "metadata": {},
   "source": [
    "## 3. Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3558293-9fd1-4c0c-af8a-ee35c2cf4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_targets(elm, ignore=['Other', 'None']):\n",
    "    \"\"\"\n",
    "    This function merges annotated targets from each annotator\n",
    "    into a single list when annotators agree\n",
    "    \"\"\"\n",
    "    targets = elm['annotators']['target']\n",
    "    counts = reduce(lambda x, y: Counter(x) + Counter(y) , targets)\n",
    "    result = [target for target, count in counts.items() if count > 1]\n",
    "    if result:\n",
    "        return {'target': result}\n",
    "    else:\n",
    "        return {'target': []}\n",
    "\n",
    "he_dataset = he_dataset.map(get_common_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791dbaf3-634e-426a-8085-4ef7c6d2c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_communites(targets, top=10):\n",
    "    target_counts = reduce(lambda x, y: Counter(x) + Counter(y) , targets)\n",
    "    top_targets, _ =  zip(*target_counts.most_common(top))\n",
    "    return set(top_targets)\n",
    "\n",
    "TOP = get_top_communites(he_dataset['test']['target'])\n",
    "\n",
    "def filter_top_target(elm):\n",
    "    \"\"\"\n",
    "    This function filteras the identity groups targeted\n",
    "    in each item with the top 10 most common identity groups\n",
    "    \"\"\"\n",
    "    targets = set(elm['target']) & TOP\n",
    "    return {'target': targets}\n",
    "    \n",
    "he_dataset = he_dataset.map(filter_top_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a881d-365f-43f2-93d8-991b189e4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(elm):\n",
    "    \"\"\"\n",
    "    This fuction gets a ground truth label from annotators labels\n",
    "    \"\"\"\n",
    "    label_map = {0: 1, # hatespech -> 1\n",
    "                 1: 0, # normal -> 0\n",
    "                 2: 1} # abusive -> 1\n",
    "\n",
    "    labels = elm['annotators']['label']\n",
    "    max_label = max(labels, key=labels.count)\n",
    "    return {'label': label_map[max_label]}\n",
    "    \n",
    "he_dataset = he_dataset.map(get_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615aadf-7744-4798-8a1f-65f316395ee5",
   "metadata": {},
   "source": [
    "## 4. Download Modle and Process Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ffa45-7e76-4b32-9bcf-2851ac8152c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "he_dataset.set_format(\"pt\", columns=[\"post_tokens\"], output_all_columns=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\")\n",
    "\n",
    "def process(examples):\n",
    "    bert_tokens =  tokenizer(examples['text'], return_tensors=\"pt\")\n",
    "    output = model(**bert_tokens)\n",
    "    return {\"output\": softmax(output['logits'], dim=-1).flatten()}\n",
    "\n",
    "test_ds = he_dataset['test'].map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189c557-9162-4812-afae-94a4c333b5cc",
   "metadata": {},
   "source": [
    "## 5. Get Bias Metric form Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ae687-2834-4f1d-9d52-011b695e4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('Intel/bias_auc')\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd013db-5d0f-46d1-9c70-e0b1c870ad47",
   "metadata": {},
   "source": [
    "## 6. Run Bias Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b37ab-b6b3-4d76-9cbb-df16493ae6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.add_batch(target=test_ds['target'],\n",
    "                 label=test_ds['label'],\n",
    "                 output=test_ds['output'])\n",
    "\n",
    "subgroups = set(group for group_list in test_ds['target'] for group in group_list) - set(['Disability'])\n",
    "\n",
    "metric_output = metric.compute(subgroups = subgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aec856-0d1b-4fb0-942a-5d5d00868479",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271133ca-0ddd-4f54-8448-ad660a76c943",
   "metadata": {},
   "source": [
    "## 7. Transform Output for Model Card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85a523-848b-4da0-995a-3082a992d28d",
   "metadata": {},
   "source": [
    "Mode Card Generator take two pandas dataframes as input. We will creat a `metrics_by_group` dataframe from the Bias AUC metric above as well as a `metrics_by_threshold` containing performance metrics at threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1e022-2f78-4584-8306-b03323c1b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_group = (pd.DataFrame.from_dict(metric_output).\n",
    "      T.\n",
    "      reset_index().\n",
    "      rename({'index': 'group'}, axis=1))\n",
    "metrics_by_group['feature'] = ['target'] * len(metrics_by_group)\n",
    "metrics_by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a65a63-8aca-4ed8-86c8-03a2aab2f90c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "thetas = np.linspace(0, 1, 1001)\n",
    "y_pred_prob = test_ds['output'][:,1]\n",
    "\n",
    "metrics_dict ={\n",
    "    'threshold': thetas,\n",
    "    'precision': [precision_score(test_ds['label'], y_pred_prob > theta) for theta in thetas],\n",
    "    'recall': [recall_score(test_ds['label'], y_pred_prob > theta) for theta in thetas],\n",
    "    'f1': [f1_score(test_ds['label'], y_pred_prob > theta) for theta in thetas],\n",
    "    'accuracy' : [accuracy_score(test_ds['label'], y_pred_prob > theta) for theta in thetas]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e59c1-2ad0-4add-b60b-4a9d64654bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_threshold = pd.DataFrame.from_dict(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3456d-a33e-410d-b706-4765a7504c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387c982-b7fb-4043-b377-d62c2dda9d74",
   "metadata": {},
   "source": [
    "## 8. Build Model Card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3829b2-514b-42ba-ad14-798256f7dad5",
   "metadata": {},
   "source": [
    "Simply add the dataframes into the `ModelCardGen.generate` class method to build a model card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede251f4-8531-4c8f-aacc-edb13bdf3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc =  {\n",
    "    \"schema_version\": \"0.0.1\",\n",
    "    \"model_details\": {\n",
    "        \"name\": \"Deep Learning Models for Multilingual Hate Speech Detection\",\n",
    "        \"version\": {\n",
    "            \"name\": \"25d0e4d9122d2a5c283e07405a325e3dfd4a73b3\",\n",
    "            \"date\": \"2020\"\n",
    "        },\n",
    "        \"graphics\": {},\n",
    "\n",
    "        \"citations\": [\n",
    "             {\n",
    "                \"citation\": '''@article{aluru2020deep,\n",
    "                title={Deep Learning Models for Multilingual Hate Speech Detection},\n",
    "                author={Aluru, Sai Saket and Mathew, Binny and Saha, Punyajoy and Mukherjee, Animesh},\n",
    "                journal={arXiv preprint arXiv:2004.06465},\n",
    "                year={2020}\n",
    "                }'''\n",
    "             },\n",
    "        ],\n",
    "        \"overview\": 'This model is used detecting hatespeech in English language. The mono in the name refers to the monolingual setting, where the model is trained using only English language data. It is finetuned on multilingual bert model. The model is trained with different learning rates and the best validation score achieved is 0.726030 for a learning rate of 2e-5. Training code can be found here https://github.com/punyajoy/DE-LIMIT',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c57159-ad0f-4f02-8ea2-1364d195eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcg = ModelCardGen.generate(metrics_by_group=metrics_by_group, metrics_by_threshold=metrics_by_threshold, model_card=mc)\n",
    "mcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0700c08-f41c-4f93-a476-1976a5c46b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcg.export_html('ModelCard.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7022c-a9fe-4ae4-b75c-d08cc0ca8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from plotly.io import to_html, templates\n",
    "from plotly.offline import init_notebook_mode, get_plotlyjs\n",
    "fig = px.line(x=[\"a\",\"b\",\"c\"], y=[1,3,2], title=\"sample figure\")\n",
    "html_content = to_html(fig, include_plotlyjs=\"require\", full_html=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c870b98-d995-4c5e-b25e-30bfff8104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
